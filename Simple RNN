import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
# 1. Mapping
chars = ['h','e','l','o']
char_to_idx = {c:i for i,c in enumerate(chars)}
idx_to_char = {i:c for c,i in char_to_idx.items()}
# 2. Data (hello → prediction)
input_seq = [0,1,2,2] # h e l l
target_seq = [1,2,2,3] # e l l o
X = np.array(input_seq).reshape(1,-1)
y = np.array(target_seq).reshape(1,-1)
# 3. Model
vocab_size = len(chars)
model = Sequential([
Embedding(vocab_size, 8, input_length=X.shape[1]),
SimpleRNN(8, return_sequences=True),
Dense(vocab_size, activation='softmax')
])
model.compile('adam', 'sparse_categorical_crossentropy')
# 4. Train & Predict
model.fit(X, y, epochs=100, verbose=0)
pred = model.predict(np.array([[char_to_idx['h']]]), verbose=0)
idx = np.argmax(pred[0,0])
print(f"After 'h' → '{idx_to_char[idx]}'")
